{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "llm = ChatGoogleGenerativeAI(model = \"gemini-1.5-pro\"\t , temperature = 0.7 , max_tokens=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY  = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "llm = ChatGroq(model=\"Gemma2-9b-It\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"Write 5 short captions (max 8 words each) for a social video ad. Use a hook and storytelling style. Topic: {topic}\"\n",
    ")\n",
    "\n",
    "def script_writer(state: dict) -> dict:\n",
    "    prompt = prompt_template.format_messages(topic=state[\"prompt\"])\n",
    "    response = llm(prompt)\n",
    "    text = response.content.strip()\n",
    "    print(response)\n",
    "    captions = [line.strip(\"-• \").strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "    return {**state, \"captions\": captions}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Here are 5 short captions (max 8 words each) for a car social video ad, using a hook and storytelling style:\\n\\n1. **Craving adventure? This car is ready.**\\n2. **Escape the ordinary.  Hit the open road.**\\n3. **One drive.  Endless possibilities.**\\n4. **Where will your journey take you?**\\n5. **Built for life.  Live it to the fullest.** \\n\\n\\nLet me know if you'd like more options! \\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 39, 'total_tokens': 148, 'completion_time': 0.198181818, 'prompt_time': 0.002275503, 'queue_time': 0.24867157699999998, 'total_time': 0.200457321}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--02c521bd-9d01-4fda-adc1-29a018bfab56-0' usage_metadata={'input_tokens': 39, 'output_tokens': 109, 'total_tokens': 148}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Here are 5 short captions (max 8 words each) for a car social video ad, using a hook and storytelling style:',\n",
       " '1. **Craving adventure? This car is ready.**',\n",
       " '2. **Escape the ordinary.  Hit the open road.**',\n",
       " '3. **One drive.  Endless possibilities.**',\n",
       " '4. **Where will your journey take you?**',\n",
       " '5. **Built for life.  Live it to the fullest.**',\n",
       " \"Let me know if you'd like more options!\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {\"prompt\": \"Advertisement for Car\"}\n",
    "state = script_writer(state)\n",
    "state[\"captions\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "def voice_actor(state: dict) -> dict:\n",
    "    captions = state[\"captions\"]\n",
    "    output_dir = \"outputs/audio\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    audio_paths = []\n",
    "\n",
    "    for i, caption in enumerate(captions):\n",
    "        file_path = os.path.join(output_dir, f\"caption_{i}.mp3\")\n",
    "        gTTS(text=caption, lang='en').save(file_path)\n",
    "        audio_paths.append(file_path)\n",
    "\n",
    "    return {**state, \"audio_paths\": audio_paths}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/audio/caption_0.mp3',\n",
       " 'outputs/audio/caption_1.mp3',\n",
       " 'outputs/audio/caption_2.mp3',\n",
       " 'outputs/audio/caption_3.mp3',\n",
       " 'outputs/audio/caption_4.mp3',\n",
       " 'outputs/audio/caption_5.mp3',\n",
       " 'outputs/audio/caption_6.mp3']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = voice_actor(state)\n",
    "state[\"audio_paths\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "def graphic_designer(state: dict) -> dict:\n",
    "    captions = state[\"captions\"]\n",
    "    output_dir = \"outputs/images\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_paths = []\n",
    "\n",
    "    client = InferenceClient(\n",
    "        model=\"black-forest-labs/FLUX.1-dev\",\n",
    "        provider=\"nebius\",\n",
    "        api_key=os.environ[\"HF_API_TOKEN\"]\n",
    "    )\n",
    "\n",
    "    for i, caption in enumerate(captions):\n",
    "        prompt = f\"{caption}, realistic style\"\n",
    "        try:\n",
    "            image = client.text_to_image(prompt)\n",
    "            img_path = os.path.join(output_dir, f\"image_{i}.png\")\n",
    "            image.save(img_path)\n",
    "            image_paths.append(img_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[✗] Error generating image for caption {i}: {e}\")\n",
    "\n",
    "    return {**state, \"image_paths\": image_paths}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✗] Error generating image for caption 0: 402 Client Error: Payment Required for url: https://router.huggingface.co/nebius/v1/images/generations (Request ID: Root=1-686d3dd0-7ff8d159738c9a047f68710f;89d9fed7-28eb-4f74-a285-888620f7a2ff)\n",
      "\n",
      "You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.\n",
      "[✗] Error generating image for caption 1: 402 Client Error: Payment Required for url: https://router.huggingface.co/nebius/v1/images/generations (Request ID: Root=1-686d3dd1-5e11c2591e63d6c720f26410;079c9070-35b8-4bb0-9416-4214f82c2810)\n",
      "\n",
      "You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.\n",
      "[✗] Error generating image for caption 2: 402 Client Error: Payment Required for url: https://router.huggingface.co/nebius/v1/images/generations (Request ID: Root=1-686d3dd1-73e7a610562a31bc6c14a8e9;48d44dd4-4f59-4afe-ae4d-9d98ec92bc63)\n",
      "\n",
      "You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.\n",
      "[✗] Error generating image for caption 3: 402 Client Error: Payment Required for url: https://router.huggingface.co/nebius/v1/images/generations (Request ID: Root=1-686d3dd2-5aecca645720f03e545cb4fc;8138e2fc-0f39-4216-85bb-95c3e33a0a25)\n",
      "\n",
      "You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.\n",
      "[✗] Error generating image for caption 4: 402 Client Error: Payment Required for url: https://router.huggingface.co/nebius/v1/images/generations (Request ID: Root=1-686d3dd2-67b69ced0170dd2e0e9e1b77;04719214-4b0d-4d6b-9e18-6fb6409c13e3)\n",
      "\n",
      "You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.\n",
      "[✗] Error generating image for caption 5: 402 Client Error: Payment Required for url: https://router.huggingface.co/nebius/v1/images/generations (Request ID: Root=1-686d3dd2-090158c85d6839417127d90a;e23080e7-f9f2-43e8-a411-fd61a8f58481)\n",
      "\n",
      "You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.\n",
      "[✗] Error generating image for caption 6: 402 Client Error: Payment Required for url: https://router.huggingface.co/nebius/v1/images/generations (Request ID: Root=1-686d3dd2-5289b4d240755d510d93db12;bfe79a9c-87a9-4e3a-9de0-fc6274425279)\n",
      "\n",
      "You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graphic_designer(state)\n",
    "state[\"image_paths\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Created: outputs/final/clip_0.mp4\n",
      "[✓] Created: outputs/final/clip_1.mp4\n",
      "[✓] Created: outputs/final/clip_2.mp4\n",
      "[✓] Created: outputs/final/clip_3.mp4\n",
      "[✓] Created: outputs/final/clip_4.mp4\n",
      "[✓] Created: outputs/final/clip_5.mp4\n",
      "[✓] Created: outputs/final/clip_6.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"outputs/final/clip_0.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import ffmpeg\n",
    "from IPython.display import Video, display\n",
    "\n",
    "def director(state: dict) -> dict:\n",
    "    \n",
    "    base_dir = \"outputs\"\n",
    "    images_dir = os.path.join(base_dir, \"images\")\n",
    "    audio_dir = os.path.join(base_dir, \"audio\")\n",
    "    final_dir = os.path.join(base_dir, \"final\")\n",
    "    os.makedirs(final_dir, exist_ok=True)\n",
    "\n",
    "    # List and sort files to align pairs by order\n",
    "    image_files = sorted([f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    audio_files = sorted([f for f in os.listdir(audio_dir) if f.lower().endswith(('.mp3', '.wav', '.aac'))])\n",
    "\n",
    "    video_paths = []\n",
    "\n",
    "    # Process pairs - take min length to avoid out of index\n",
    "    for i in range(min(len(image_files), len(audio_files))):\n",
    "        image_path = os.path.join(images_dir, image_files[i])\n",
    "        audio_path = os.path.join(audio_dir, audio_files[i])\n",
    "        out_path = os.path.join(final_dir, f\"clip_{i}.mp4\")\n",
    "\n",
    "        try:\n",
    "            image_input = ffmpeg.input(image_path, loop=1, t=5)  # loop image for 5 seconds\n",
    "            audio_input = ffmpeg.input(audio_path)\n",
    "\n",
    "            (\n",
    "                ffmpeg\n",
    "                .output(image_input, audio_input, out_path, vcodec='libx264', acodec='aac', shortest=None)\n",
    "                .run(overwrite_output=True, quiet=True)\n",
    "            )\n",
    "            video_paths.append(out_path)\n",
    "            print(f\"[✓] Created: {out_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[✗] Error creating clip {i}:\", e)\n",
    "\n",
    "    if video_paths:\n",
    "        display(Video(video_paths[0]))\n",
    "\n",
    "    return {**state, \"video_paths\": video_paths}\n",
    "\n",
    "# Run the function\n",
    "state = {}\n",
    "state = director(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Created: outputs/final/clip_0.mp4\n",
      "[✓] Created: outputs/final/clip_1.mp4\n",
      "[✓] Created: outputs/final/clip_2.mp4\n",
      "[✓] Created: outputs/final/clip_3.mp4\n",
      "[✓] Created: outputs/final/clip_4.mp4\n",
      "[✓] Created: outputs/final/clip_5.mp4\n",
      "[✓] Created: outputs/final/clip_6.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"outputs/final/clip_0.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = director(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import os\n",
    "from IPython.display import Video, display\n",
    "\n",
    "def director(state: dict) -> dict:\n",
    "    audio_paths = state[\"audio_paths\"]\n",
    "    image_paths = state[\"image_paths\"]\n",
    "    captions = state[\"captions\"]\n",
    "\n",
    "    final_dir = \"outputs/final\"\n",
    "    os.makedirs(final_dir, exist_ok=True)\n",
    "    video_paths = []\n",
    "\n",
    "    for i, (audio, image, caption) in enumerate(zip(audio_paths, image_paths, captions)):\n",
    "        out_path = os.path.join(final_dir, f\"clip_{i}.mp4\")\n",
    "        try:\n",
    "            image_input = ffmpeg.input(image, loop=1, t=5)\n",
    "            audio_input = ffmpeg.input(audio)\n",
    "\n",
    "            (\n",
    "                ffmpeg\n",
    "                .output(image_input, audio_input, out_path, vcodec='libx264', acodec='aac', strict='experimental', shortest=None)\n",
    "                .run(overwrite_output=True, quiet=True)\n",
    "            )\n",
    "            video_paths.append(out_path)\n",
    "            print(f\"[✓] Created: {out_path}\")\n",
    "        except ffmpeg.Error as e:\n",
    "            print(f\"[✗] Error for clip {i}:\", e)\n",
    "\n",
    "    if video_paths:\n",
    "        display(Video(video_paths[0]))\n",
    "\n",
    "    return {**state, \"video_paths\": video_paths}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'audio_paths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mdirector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 6\u001b[0m, in \u001b[0;36mdirector\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdirector\u001b[39m(state: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m     audio_paths \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio_paths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m     image_paths \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_paths\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m     captions \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaptions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'audio_paths'"
     ]
    }
   ],
   "source": [
    "state = director(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import os\n",
    "\n",
    "def merge_clips(video_paths, output_path=\"outputs/final/final_video.mp4\"):\n",
    "\n",
    "    if not video_paths:\n",
    "        print(\"No video clips to merge.\")\n",
    "        return\n",
    "\n",
    "    # Create temporary text file with all paths\n",
    "    list_file = \"outputs/final/merge_list.txt\"\n",
    "    with open(list_file, \"w\") as f:\n",
    "        for path in video_paths:\n",
    "            f.write(f\"file '{os.path.abspath(path)}'\\n\")\n",
    "\n",
    "    # Merge using ffmpeg concat demuxer\n",
    "    try:\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(list_file, format='concat', safe=0)\n",
    "            .output(output_path, c='copy')\n",
    "            .run(overwrite_output=True, quiet=True)\n",
    "        )\n",
    "        print(f\"[✓] Merged into: {output_path}\")\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"[✗] Merge error:\", e)\n",
    "\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Merged into: outputs/final/final_video.mp4\n"
     ]
    }
   ],
   "source": [
    "merged_path = merge_clips(state[\"video_paths\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"outputs/final/final_video.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Video, display\n",
    "display(Video(merged_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aivideo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
